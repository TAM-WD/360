'''
–°–∫—Ä–∏–ø—Ç –ø–æ–∑–≤–æ–ª—è–µ—Ç –Ω–∞–π—Ç–∏ –∏ —É–¥–∞–ª–∏—Ç—å –ø–∏—Å—å–º–∞ –æ—Ç –æ–ø—Ä–µ–¥–µ–ª–µ–Ω–Ω–æ–≥–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥ –∏–∑ –ø–æ—á—Ç–æ–≤—ã—Ö —è—â–∏–∫–æ–≤ —Å–æ—Ç—Ä—É–¥–Ω–∏–∫–æ–≤ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏ –Ø–Ω–¥–µ–∫—Å 360.

–î–ª—è –∑–∞–ø—É—Å–∫–∞ —Å–∫—Ä–∏–ø—Ç–∞ –Ω–µ–æ–±—Ö–æ–¥–∏–º Python –≤–µ—Ä—Å–∏–∏ 3.10 –∏–ª–∏ –≤—ã—à–µ, –∞ —Ç–∞–∫–∂–µ –±–∏–±–ª–∏–æ—Ç–µ–∫–∏ aioimaplib, requests, urllib3 –∏ pydantic.

–£—Å—Ç–∞–Ω–æ–≤–∏—Ç—å –∏—Ö –º–æ–∂–Ω–æ —Å –ø–æ–º–æ—â—å—é pip:
pip install aioimaplib requests urllib3 pydantic

–î–ª—è –∑–∞–ø—É—Å–∫–∞ —Å–∫—Ä–∏–ø—Ç–∞ –º–æ–∂–Ω–æ –∏—Å–ø–æ–ª—å–∑–æ–≤–∞—Ç—å –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è –∏–ª–∏ –∏–∑–º–µ–Ω–∏—Ç—å –∑–Ω–∞—á–µ–Ω–∏—è –≤ —Ñ—É–Ω–∫—Ü–∏–∏ get_settings():

–ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:
    OAUTH_TOKEN - OAuth —Ç–æ–∫–µ–Ω –¥–ª—è –¥–æ—Å—Ç—É–ø–∞ –∫ API –Ø–Ω–¥–µ–∫—Å 360
    ORGANIZATION_ID - ID –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏
    APPLICATION_CLIENT_ID - Client ID —Å–µ—Ä–≤–∏—Å–Ω–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    APPLICATION_CLIENT_SECRET - Client Secret —Å–µ—Ä–≤–∏—Å–Ω–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è

–õ–∏–±–æ –≤ —Ñ—É–Ω–∫—Ü–∏–∏ get_settings() —É–∫–∞–∂–∏—Ç–µ:
    HARDCODED_TOKEN = "" # OAuth —Ç–æ–∫–µ–Ω
    HARDCODED_ORG_ID = "" # ID –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏
    HARDCODED_CLIENT_ID = "" # Client ID —Å–µ—Ä–≤–∏—Å–Ω–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
    HARDCODED_CLIENT_SECRET = "" # Client Secret —Å–µ—Ä–≤–∏—Å–Ω–æ–≥–æ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è

–¢–∞–∫–∂–µ –ø—Ä–µ–¥–≤–∞—Ä–∏—Ç–µ–ª—å–Ω–æ –Ω—É–∂–Ω–æ:
1. –ü–æ–ª—É—á–∏—Ç—å OAuth —Ç–æ–∫–µ–Ω —Å –ø—Ä–∞–≤–∞–º–∏ –Ω–∞ —á—Ç–µ–Ω–∏–µ –∞—É–¥–∏—Ç-–ª–æ–≥–æ–≤ (ya360_security:audit_log_mail)
2. –ù–∞—Å—Ç—Ä–æ–∏—Ç—å —Å–µ—Ä–≤–∏—Å–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ —Å –ø—Ä–∞–≤–∞–º–∏ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–æ–≤ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–π —Å –ø—Ä–∞–≤–∞–º–∏ mail:imap_full

–ü–∞—Ä–∞–º–µ—Ç—Ä—ã –∑–∞–ø—É—Å–∫–∞ (–æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ):
    --from - Email –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è
    --date - –î–∞—Ç–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ DD-MM-YYYY
    --time-from - –ù–∞—á–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ HH:MM:SS
    --time-to - –ö–æ–Ω–µ—á–Ω–æ–µ –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞ –≤ —Ñ–æ—Ä–º–∞—Ç–µ HH:MM:SS
    
–í–ê–ñ–ù–û: 
- –í—Ä–µ–º—è —É–∫–∞–∑—ã–≤–∞–µ—Ç—Å—è –≤ –º–æ—Å–∫–æ–≤—Å–∫–æ–º —á–∞—Å–æ–≤–æ–º –ø–æ—è—Å–µ (UTC+3). –°–∫—Ä–∏–ø—Ç –∞–≤—Ç–æ–º–∞—Ç–∏—á–µ—Å–∫–∏ –∫–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ—Ç –µ–≥–æ –≤ UTC.
- –ï—Å–ª–∏ –Ω—É–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å –∑–∞ –Ω–µ—Å–∫–æ–ª—å–∫–æ –¥–Ω–µ–π - –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç –Ω–µ—Å–∫–æ–ª—å–∫–æ —Ä–∞–∑ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ –¥–Ω—è –æ—Ç–¥–µ–ª—å–Ω–æ.

–ü—Ä–∏–º–µ—Ä—ã:
–ü–æ–∏—Å–∫ –∑–∞ –∫–æ–Ω–∫—Ä–µ—Ç–Ω—ã–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π –ø—Ä–æ–º–µ–∂—É—Ç–æ–∫ –≤ –æ–¥–∏–Ω –¥–µ–Ω—å
python deleting_emails_by_sender.py --from sender@example.com --date 29-01-2026 --time-from 10:35:00 --time-to 10:40:00

–ü–æ–∏—Å–∫ –∑–∞ –≤–µ—Å—å —Ä–∞–±–æ—á–∏–π –¥–µ–Ω—å (—Å 9:00 –¥–æ 18:00)
python deleting_emails_by_sender.py --from sender@example.com --date 29-01-2026 --time-from 09:00:00 --time-to 18:00:00

–ü–æ–∏—Å–∫ –∑–∞ –≤–µ—Å—å –¥–µ–Ω—å (—Å 00:00 –¥–æ 23:59)
python deleting_emails_by_sender.py --from sender@example.com --date 29-01-2026 --time-from 00:00:00 --time-to 23:59:59


–í–ù–ò–ú–ê–ù–ò–ï: –°–∫—Ä–∏–ø—Ç –±–µ–∑–≤–æ–∑–≤—Ä–∞—Ç–Ω–æ —É–¥–∞–ª—è–µ—Ç –ø–∏—Å—å–º–∞! –ü–µ—Ä–µ–¥ –∑–∞–ø—É—Å–∫–æ–º —É–±–µ–¥–∏—Ç–µ—Å—å, —á—Ç–æ —É–∫–∞–∑–∞–Ω—ã –ø—Ä–∞–≤–∏–ª—å–Ω—ã–µ –∫—Ä–∏—Ç–µ—Ä–∏–∏ –ø–æ–∏—Å–∫–∞.
'''

import argparse
import asyncio
import concurrent.futures
import enum
import logging
import os
import re
import ssl
import sys
import io
import binascii
import traceback
import time
import socket
import gc
from dataclasses import dataclass
from datetime import datetime, timedelta
from http import HTTPStatus
from os import environ
from textwrap import dedent
from typing import Optional, Union, Dict
from threading import Lock
from collections import defaultdict

if sys.stdout.encoding != 'utf-8':
    sys.stdout = io.TextIOWrapper(sys.stdout.buffer, encoding='utf-8', errors='replace')
    sys.stderr = io.TextIOWrapper(sys.stderr.buffer, encoding='utf-8', errors='replace')

if sys.platform == 'win32':
    asyncio.set_event_loop_policy(asyncio.WindowsProactorEventLoopPolicy())
    print("Windows detected: using ProactorEventLoop (no file descriptor limit)")

import aioimaplib
import requests
import urllib3
from pydantic import BaseModel, Field, ConfigDict
from urllib3.exceptions import InsecureRequestWarning

urllib3.disable_warnings(InsecureRequestWarning)

SCRIPT_NAME = "deleting_messages"
RUN_TIMESTAMP = datetime.now().strftime('%Y%m%d_%H%M%S')
OUTPUT_DIR = f"{SCRIPT_NAME}_{RUN_TIMESTAMP}"
os.makedirs(OUTPUT_DIR, exist_ok=True)

LOG_FILE = os.path.join(OUTPUT_DIR, f"logs.log")
DELETED_MESSAGES_FILE = os.path.join(OUTPUT_DIR, "deleted_messages.txt")
FAILED_RECIPIENTS_FILE = os.path.join(OUTPUT_DIR, "failed_recipients.txt")

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s - %(levelname)s - %(message)s",
    handlers=[
        logging.FileHandler(LOG_FILE, encoding='utf-8'),
        logging.StreamHandler(sys.stdout)
    ]
)
logger = logging.getLogger("deleting messages")

logging.getLogger('aioimaplib.aioimaplib').setLevel(logging.WARNING)

AUDIT_LOG_PAGE_SIZE = 100
DEFAULT_IMAP_SERVER = "imap.yandex.ru"
DEFAULT_IMAP_PORT = 993
DEFAULT_360_API_URL = "https://api360.yandex.net"
DEFAULT_OAUTH_API_URL = "https://oauth.yandex.ru/token"
OAUTH_TOKEN_ARG = "OAUTH_TOKEN"
ORGANIZATION_ID_ARG = "ORGANIZATION_ID"
APPLICATION_CLIENT_ID_ARG = "APPLICATION_CLIENT_ID"
APPLICATION_CLIENT_SECRET_ARG = "APPLICATION_CLIENT_SECRET"
EXIT_CODE = 1

SEARCH_DATE_RANGE = None

MAX_CONCURRENT_IMAP = 2
BATCH_SIZE = 50
BATCH_PAUSE = 3
IMAP_CONNECT_TIMEOUT = 60 
IMAP_SELECT_TIMEOUT = 90  
IMAP_SEARCH_TIMEOUT = 60 
IMAP_LIST_TIMEOUT = 30
CONNECTION_DELAY = 0.3  
RECIPIENT_DELAY = 0.3
GC_INTERVAL = 10

if sys.platform == 'win32':
    MAX_CONCURRENT_IMAP = 2
    IMAP_CONNECT_TIMEOUT = 30
    BATCH_SIZE = 20
    BATCH_PAUSE = 5
    CONNECTION_DELAY = 0.8
    GC_INTERVAL = 5
    logger.info("Windows detected: adjusted parameters for stability")
    logger.info(f"  - MAX_CONCURRENT_IMAP: {MAX_CONCURRENT_IMAP}")
    logger.info(f"  - BATCH_SIZE: {BATCH_SIZE}")
    logger.info(f"  - IMAP_CONNECT_TIMEOUT: {IMAP_CONNECT_TIMEOUT}")
    logger.info(f"  - CONNECTION_DELAY: {CONNECTION_DELAY}")

_token_cache: Dict[str, tuple[str, float]] = {}
_token_cache_lock = Lock()
_http_session: Optional[requests.Session] = None
_imap_connection_lock = asyncio.Lock()

# –ì–ª–æ–±–∞–ª—å–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è
_deletion_stats = {
    'total_deleted': 0,
    'recipients_with_deletions': 0,
    'recipients_without_deletions': 0,
    'recipients_with_errors': 0,
    'lock': Lock()
}


def add_deletion_stats(deleted_count: int, has_error: bool = False):
    """–î–æ–±–∞–≤–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —É–¥–∞–ª–µ–Ω–∏—è"""
    with _deletion_stats['lock']:
        if has_error:
            _deletion_stats['recipients_with_errors'] += 1
        else:
            _deletion_stats['total_deleted'] += deleted_count
            if deleted_count > 0:
                _deletion_stats['recipients_with_deletions'] += 1
            else:
                _deletion_stats['recipients_without_deletions'] += 1


def get_deletion_stats() -> dict:
    """–ü–æ–ª—É—á–∏—Ç—å —Ç–µ–∫—É—â—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —É–¥–∞–ª–µ–Ω–∏—è"""
    with _deletion_stats['lock']:
        return {
            'total_deleted': _deletion_stats['total_deleted'],
            'recipients_with_deletions': _deletion_stats['recipients_with_deletions'],
            'recipients_without_deletions': _deletion_stats['recipients_without_deletions'],
            'recipients_with_errors': _deletion_stats['recipients_with_errors']
        }


def reset_deletion_stats():
    """–°–±—Ä–æ—Å–∏—Ç—å —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —É–¥–∞–ª–µ–Ω–∏—è"""
    with _deletion_stats['lock']:
        _deletion_stats['total_deleted'] = 0
        _deletion_stats['recipients_with_deletions'] = 0
        _deletion_stats['recipients_without_deletions'] = 0
        _deletion_stats['recipients_with_errors'] = 0


def get_http_session() -> requests.Session:
    global _http_session
    if _http_session is None:
        _http_session = requests.Session()
        adapter = requests.adapters.HTTPAdapter(
            pool_connections=10,
            pool_maxsize=50,
            max_retries=3,
            pool_block=False
        )
        _http_session.mount('https://', adapter)
        _http_session.mount('http://', adapter)
    return _http_session


def get_cached_token(email: str) -> Optional[str]:
    with _token_cache_lock:
        if email in _token_cache:
            token, expiry = _token_cache[email]
            if time.time() < (expiry - 300):
                logger.debug(f"üîë Using cached token for {email}")
                return token
            else:
                logger.debug(f"üîë Cached token expired for {email}")
                del _token_cache[email]
    return None


def cache_token(email: str, token: str, expires_in: int):
    with _token_cache_lock:
        expiry = time.time() + expires_in
        _token_cache[email] = (token, expiry)
        logger.debug(f"üîë Cached token for {email} (expires in {expires_in}s)")

def force_cleanup():
    try:
        gc.collect()
        logger.debug("üßπ Garbage collection completed")
    except Exception as e:
        logger.debug(f"GC error: {e}")


def decode_modified_utf7(s: str) -> str:
    if not s or '&' not in s:
        return s
    
    result = []
    i = 0
    
    while i < len(s):
        if s[i] == '&':
            end = s.find('-', i + 1)
            if end == -1:
                result.append(s[i:])
                break
            
            if end == i + 1:
                result.append('&')
                i = end + 1
            else:
                encoded = s[i + 1:end]
                try:
                    encoded_fixed = encoded.replace(',', '/')
                    padding = (4 - len(encoded_fixed) % 4) % 4
                    encoded_fixed += '=' * padding
                    decoded_bytes = binascii.a2b_base64(encoded_fixed.encode('ascii'))
                    decoded_str = decoded_bytes.decode('utf-16-be', errors='replace')
                    result.append(decoded_str)
                except Exception:
                    result.append(s[i:end + 1])
                i = end + 1
        else:
            result.append(s[i])
            i += 1
    
    return ''.join(result)


def escape_imap_folder_name(folder_name: str) -> str:
    if not folder_name:
        return folder_name
    
    result = folder_name.replace('\\', '\\\\')
    result = result.replace('"', '\\"')
    
    return result


def map_folder(folder: Optional[bytes]) -> Optional[tuple[str, str]]:
    if not folder:
        return None
        
    if folder == b"LIST Completed.":
        return None
    
    try:
        if isinstance(folder, bytearray):
            return None
            
        decoded = folder.decode("utf-8", errors='replace')
    except:
        try:
            decoded = folder.decode("ascii", errors='replace')
        except:
            logger.debug(f"map_folder: failed to decode")
            return None
    
    if '\\Noselect' in decoded:
        return None
    
    if re.search(r'\{\d+\}$', decoded.strip()):
        return None
    
    parts = decoded.split('"|"')
    
    if len(parts) >= 2:
        folder_name_raw = parts[-1].strip().strip('"')
    elif '" "|" ' in decoded:
        folder_name_raw = decoded.split('" "|" ')[-1].strip()
    else:
        tokens = decoded.split()
        if len(tokens) >= 3:
            delimiter_index = None
            for i, token in enumerate(tokens):
                if '"|"' in token:
                    delimiter_index = i
                    break
            
            if delimiter_index is not None:
                folder_name_raw = ' '.join(tokens[delimiter_index + 1:]).strip('"')
            else:
                folder_name_raw = tokens[-1].strip('"')
        else:
            logger.debug(f"map_folder: not enough tokens in '{decoded[:50]}...'")
            return None
    
    folder_name_raw = folder_name_raw.strip().replace('\r', '').replace('\n', '')
    
    if not folder_name_raw or folder_name_raw in ['NIL']:
        logger.debug(f"map_folder: empty or NIL folder name")
        return None
    
    folder_name_decoded = decode_modified_utf7(folder_name_raw)
    folder_name_escaped = escape_imap_folder_name(folder_name_raw)
    
    return (f'"{folder_name_escaped}"', folder_name_decoded if folder_name_decoded else folder_name_raw)


def extract_emails(field_value: str) -> list[str]:
    if not field_value:
        return []
    
    email_pattern = r'<([^>]+)>|([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})'
    
    emails = []
    for match in re.finditer(email_pattern, field_value):
        email = match.group(1) or match.group(2)
        if email:
            emails.append(email.strip())
    
    return emails


def arg_parser():
    parser = argparse.ArgumentParser(
        description=dedent(
            f"""
            –°–∫—Ä–∏–ø—Ç –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è –ø–∏—Å–µ–º –ø–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—é –∏ –≤—Ä–µ–º–µ–Ω–Ω–æ–º—É –¥–∏–∞–ø–∞–∑–æ–Ω—É –≤ –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏—è—Ö –Ø–Ω–¥–µ–∫—Å 360.

            –ü–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è:
            {OAUTH_TOKEN_ARG} - OAuth —Ç–æ–∫–µ–Ω,
            {ORGANIZATION_ID_ARG} - ID –æ—Ä–≥–∞–Ω–∏–∑–∞—Ü–∏–∏,
            {APPLICATION_CLIENT_ID_ARG} - Client ID –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è,
            {APPLICATION_CLIENT_SECRET_ARG} - Client Secret –ø—Ä–∏–ª–æ–∂–µ–Ω–∏—è
            """
        ),
        formatter_class=argparse.RawDescriptionHelpFormatter,
    )

    parser.add_argument(
        "--from", 
        dest="sender",
        help="Email –∞–¥—Ä–µ—Å –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è –¥–ª—è –ø–æ–∏—Å–∫–∞", 
        type=str, 
        required=True
    )
    parser.add_argument(
        "--date",
        help="–î–∞—Ç–∞ –¥–ª—è –ø–æ–∏—Å–∫–∞ (—Ñ–æ—Ä–º–∞—Ç: DD-MM-YYYY).",
        type=str,
        required=True,
    )
    parser.add_argument(
        "--time-from",
        help="–ù–∞—á–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞ –≤ –º–æ—Å–∫–æ–≤—Å–∫–æ–º —á–∞—Å–æ–≤–æ–º –ø–æ—è—Å–µ (—Ñ–æ—Ä–º–∞—Ç: HH:MM:SS)",
        type=str,
        required=True,
    )
    parser.add_argument(
        "--time-to",
        help="–ö–æ–Ω–µ—á–Ω–æ–µ –≤—Ä–µ–º—è –ø–æ–∏—Å–∫–∞ –≤ –º–æ—Å–∫–æ–≤—Å–∫–æ–º —á–∞—Å–æ–≤–æ–º –ø–æ—è—Å–µ (—Ñ–æ—Ä–º–∞—Ç: HH:MM:SS)",
        type=str,
        required=True,
    )

    return parser


def main():
    global SEARCH_DATE_RANGE
    
    parsr = arg_parser()
    args = parsr.parse_args()
    
    try:
        settings = get_settings()
    except ValueError:
        logging.error(f"–û–®–ò–ë–ö–ê: –ó–Ω–∞—á–µ–Ω–∏–µ {ORGANIZATION_ID_ARG} –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ü–µ–ª—ã–º —á–∏—Å–ª–æ–º.")
        sys.exit(EXIT_CODE)
    except KeyError as key:
        logger.error(f"–û–®–ò–ë–ö–ê: –ù–µ —É–∫–∞–∑–∞–Ω—ã –æ–±—è–∑–∞—Ç–µ–ª—å–Ω—ã–µ –ø–µ—Ä–µ–º–µ–Ω–Ω—ã–µ –æ–∫—Ä—É–∂–µ–Ω–∏—è: {key}")
        parsr.print_usage()
        sys.exit(EXIT_CODE)
    
    sender_email = args.sender
    date_str = args.date
    time_from_str = args.time_from
    time_to_str = args.time_to
    
    # –°–º–µ—â–µ–Ω–∏–µ –¥–ª—è –º–æ—Å–∫–æ–≤—Å–∫–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ (UTC+3)
    MOSCOW_UTC_OFFSET = timedelta(hours=3)
    
    try:
        # –ü–∞—Ä—Å–∏–º –¥–∞—Ç—É (–æ–¥–Ω—É)
        search_date = datetime.strptime(date_str, "%d-%m-%Y")
        
        # –ü–∞—Ä—Å–∏–º –≤—Ä–µ–º—è
        time_from = datetime.strptime(time_from_str, "%H:%M:%S").time()
        time_to = datetime.strptime(time_to_str, "%H:%M:%S").time()
        
        # –ö–æ–º–±–∏–Ω–∏—Ä—É–µ–º –¥–∞—Ç—É –∏ –≤—Ä–µ–º—è (—ç—Ç–æ –º–æ—Å–∫–æ–≤—Å–∫–æ–µ –≤—Ä–µ–º—è)
        datetime_from_moscow = datetime.combine(search_date.date(), time_from)
        datetime_to_moscow = datetime.combine(search_date.date(), time_to)
        
        # –ö–æ–Ω–≤–µ—Ä—Ç–∏—Ä—É–µ–º –∏–∑ –º–æ—Å–∫–æ–≤—Å–∫–æ–≥–æ –≤—Ä–µ–º–µ–Ω–∏ –≤ UTC (–≤—ã—á–∏—Ç–∞–µ–º 3 —á–∞—Å–∞)
        datetime_from = datetime_from_moscow - MOSCOW_UTC_OFFSET
        datetime_to = datetime_to_moscow - MOSCOW_UTC_OFFSET
        
    except ValueError as e:
        logger.error(f"–û–®–ò–ë–ö–ê: –ù–µ–≤–µ—Ä–Ω—ã–π —Ñ–æ—Ä–º–∞—Ç –¥–∞—Ç—ã/–≤—Ä–µ–º–µ–Ω–∏. –ò—Å–ø–æ–ª—å–∑—É–π—Ç–µ DD-MM-YYYY –¥–ª—è –¥–∞—Ç—ã –∏ HH:MM:SS –¥–ª—è –≤—Ä–µ–º–µ–Ω–∏")
        logger.error(f"–î–µ—Ç–∞–ª–∏: {e}")
        sys.exit(EXIT_CODE)
    
    if datetime_from > datetime_to:
        logger.error(f"–û–®–ò–ë–ö–ê: –ù–∞—á–∞–ª—å–Ω–æ–µ –≤—Ä–µ–º—è –¥–æ–ª–∂–Ω–æ –±—ã—Ç—å —Ä–∞–Ω—å—à–µ –∏–ª–∏ —Ä–∞–≤–Ω–æ –∫–æ–Ω–µ—á–Ω–æ–º—É –≤—Ä–µ–º–µ–Ω–∏")
        logger.error(f"–ü–û–î–°–ö–ê–ó–ö–ê: –ï—Å–ª–∏ –Ω—É–∂–Ω–æ —É–¥–∞–ª–∏—Ç—å –ø–∏—Å—å–º–∞ –∑–∞ –ø–µ—Ä–∏–æ–¥ —Å –≤–µ—á–µ—Ä–∞ –æ–¥–Ω–æ–≥–æ –¥–Ω—è –¥–æ —É—Ç—Ä–∞ —Å–ª–µ–¥—É—é—â–µ–≥–æ, –∑–∞–ø—É—Å—Ç–∏—Ç–µ —Å–∫—Ä–∏–ø—Ç –¥–≤–∞–∂–¥—ã:")
        logger.error(f"  1) --date {date_str} --time-from {time_from_str} --time-to 23:59:59")
        logger.error(f"  2) --date <—Å–ª–µ–¥—É—é—â–∏–π –¥–µ–Ω—å> --time-from 00:00:00 --time-to {time_to_str}")
        sys.exit(EXIT_CODE)
    
    # –£—Å—Ç–∞–Ω–∞–≤–ª–∏–≤–∞–µ–º –¥–∏–∞–ø–∞–∑–æ–Ω –¥–ª—è IMAP –ø–æ–∏—Å–∫–∞ (–∏—Å–ø–æ–ª—å–∑—É–µ–º —Ç–æ–ª—å–∫–æ –¥–∞—Ç—ã –¥–ª—è IMAP)
    after_date = datetime_from.replace(hour=0, minute=0, second=0)
    before_date = (datetime_to + timedelta(days=1)).replace(hour=0, minute=0, second=0)
    SEARCH_DATE_RANGE = (after_date, before_date)
    
    # –î–∏–∞–ø–∞–∑–æ–Ω –¥–ª—è API —Å —É—á–µ—Ç–æ–º –≤—Ä–µ–º–µ–Ω–∏
    api_after_datetime = datetime_from
    api_before_datetime = datetime_to
    
    if os.path.exists(DELETED_MESSAGES_FILE):
        os.remove(DELETED_MESSAGES_FILE)
    
    if os.path.exists(FAILED_RECIPIENTS_FILE):
        os.remove(FAILED_RECIPIENTS_FILE)
    
    # –°–±—Ä–∞—Å—ã–≤–∞–µ–º —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É —É–¥–∞–ª–µ–Ω–∏—è
    reset_deletion_stats()
    
    logger.info(f"–î–∏—Ä–µ–∫—Ç–æ—Ä–∏—è –≤—ã–≤–æ–¥–∞: {os.path.abspath(OUTPUT_DIR)}")
    logger.info(f"–õ–æ–≥-—Ñ–∞–π–ª: {LOG_FILE}")
    logger.info(f"–§–∞–π–ª —É–¥–∞–ª–µ–Ω–Ω—ã—Ö —Å–æ–æ–±—â–µ–Ω–∏–π: {DELETED_MESSAGES_FILE}")
    logger.info(f"–§–∏–ª—å—Ç—Ä –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è: {sender_email}")
    logger.info(f"–î–∞—Ç–∞ –ø–æ–∏—Å–∫–∞: {search_date.strftime('%d-%m-%Y')}")
    logger.info(f"–î–∏–∞–ø–∞–∑–æ–Ω –≤—Ä–µ–º–µ–Ω–∏ (–ú–æ—Å–∫–≤–∞ UTC+3): {datetime_from_moscow.strftime('%H:%M:%S')} –¥–æ {datetime_to_moscow.strftime('%H:%M:%S')}")
    logger.info(f"–ü–æ–ª–Ω—ã–π –¥–∏–∞–ø–∞–∑–æ–Ω datetime (UTC –¥–ª—è API): {datetime_from.strftime('%d-%m-%Y %H:%M:%S')} –¥–æ {datetime_to.strftime('%d-%m-%Y %H:%M:%S')}")
    logger.info(f"–î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç –¥–ª—è IMAP: {after_date.strftime('%d-%b-%Y')} –¥–æ {before_date.strftime('%d-%b-%Y')} (–∏—Å–∫–ª—é—á–∞—è)")
    logger.info(f"–ú–∞–∫—Å–∏–º—É–º –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö IMAP –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–π: {MAX_CONCURRENT_IMAP}")
    logger.info(f"–†–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞: {BATCH_SIZE} –ø–æ–ª—É—á–∞—Ç–µ–ª–µ–π")
    logger.info(f"–ü–∞—É–∑–∞ –º–µ–∂–¥—É –ø–∞–∫–µ—Ç–∞–º–∏: {BATCH_PAUSE} —Å–µ–∫—É–Ω–¥")
    logger.info("–°–∫—Ä–∏–ø—Ç —É–¥–∞–ª–µ–Ω–∏—è –ø–∏—Å–µ–º –∑–∞–ø—É—â–µ–Ω.")
    
    client = Client360(
        token=settings.oauth_token,
        org_id=settings.organization_id,
        client_id=settings.app_client_id,
        secret=settings.app_client_secret,
    )
    
    api_after_datetime_str = datetime_from.strftime("%Y-%m-%dT%H:%M:%SZ")
    api_before_datetime_str = datetime_to.strftime("%Y-%m-%dT%H:%M:%SZ")
    
    fetched_messages = fetch_audit_logs(
        client=client,
        sender_email=sender_email,
        datetime_from=datetime_from,
        datetime_to=datetime_to,
        datetime_from_moscow=datetime_from_moscow,
        datetime_to_moscow=datetime_to_moscow,
        after_date=api_after_datetime_str,
        before_date=api_before_datetime_str,
    )
    
    total_events = sum(len(msg_ids) for msg_ids in fetched_messages.recipient_messages.values())
    total_unique_msgids = len(fetched_messages.all_message_ids)
    
    logger.info(f"–ù–∞–π–¥–µ–Ω–æ {total_events} —Å–æ–±—ã—Ç–∏–π –≤ –∞—É–¥–∏—Ç-–ª–æ–≥–µ")
    logger.info(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö message ID: {total_unique_msgids}")
    logger.info(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—É—á–∞—Ç–µ–ª–µ–π: {len(fetched_messages.recipient_messages)}")
    
    if fetched_messages.subjects:
        logger.info(f"–ü—Ä–∏–º–µ—Ä—ã —Ç–µ–º ({min(5, len(fetched_messages.subjects))} –∏–∑ {len(fetched_messages.subjects)}):")
        for i, subject in enumerate(list(fetched_messages.subjects)[:5]):
            logger.info(f"  {i+1}. {subject}")
    
    if total_events == 0:
        logger.info("–ù–µ –Ω–∞–π–¥–µ–Ω–æ —Å–æ–±—ã—Ç–∏–π, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –∫—Ä–∏—Ç–µ—Ä–∏—è–º.")
        logger.info("–°–∫—Ä–∏–ø—Ç —É–¥–∞–ª–µ–Ω–∏—è –ø–∏—Å–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω.")
        logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {os.path.abspath(OUTPUT_DIR)}")
        return
    
    if len(fetched_messages.recipient_messages) == 0:
        logger.info("–ù–µ –Ω–∞–π–¥–µ–Ω–æ –ø–æ–ª—É—á–∞—Ç–µ–ª–µ–π –¥–ª—è —É–¥–∞–ª–µ–Ω–∏—è.")
        logger.info("–°–∫—Ä–∏–ø—Ç —É–¥–∞–ª–µ–Ω–∏—è –ø–∏—Å–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω.")
        logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {os.path.abspath(OUTPUT_DIR)}")
        return
        
    if is_deletion_approve(
        sender=sender_email,
        event_count=total_events,
        unique_msgids=total_unique_msgids,
        subjects=fetched_messages.subjects,
        recipient_messages=fetched_messages.recipient_messages
    ):
        try:
            asyncio.run(
                process_recipients_in_batches(
                    client=client, 
                    recipient_messages=fetched_messages.recipient_messages
                )
            )
        except KeyboardInterrupt:
            logger.info("–ü—Ä–æ—Ü–µ—Å—Å –ø—Ä–µ—Ä–≤–∞–Ω –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª–µ–º")
        except Exception as err:
            logger.error(f"–û—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {err}")
            logger.error(traceback.format_exc())
    
    logger.info("–°–∫—Ä–∏–ø—Ç —É–¥–∞–ª–µ–Ω–∏—è –ø–∏—Å–µ–º –∑–∞–≤–µ—Ä—à–µ–Ω.")
    logger.info(f"–†–µ–∑—É–ª—å—Ç–∞—Ç—ã —Å–æ—Ö—Ä–∞–Ω–µ–Ω—ã –≤: {os.path.abspath(OUTPUT_DIR)}")
    
    if sys.platform == 'win32':
        logger.info("–û—á–∏—Å—Ç–∫–∞ —Ä–µ—Å—É—Ä—Å–æ–≤...")
        force_cleanup()
        time.sleep(2)


async def keepalive(connector):
    try:
        if connector and hasattr(connector, 'protocol'):
            state = connector.protocol.state
            if state in ["AUTH", "SELECTED"]:
                await asyncio.wait_for(connector.noop(), timeout=5)
                return True
    except Exception as e:
        logger.debug(f"Keepalive failed: {e}")
    return False


async def safe_close(connector):
    try:
        if not connector:
            return
        
        try:
            state = connector.protocol.state if hasattr(connector, 'protocol') else None
            
            if state == "SELECTED":
                try:
                    await asyncio.wait_for(connector.close(), timeout=2)
                except:
                    pass
            
            try:
                await asyncio.wait_for(connector.logout(), timeout=2)
            except:
                pass
        except:
            pass
        
        try:
            if hasattr(connector, '_transport') and connector._transport:
                connector._transport.abort()
        except:
            pass
        
        try:
            if hasattr(connector, 'protocol'):
                connector.protocol = None
            if hasattr(connector, '_transport'):
                connector._transport = None
        except:
            pass
        
        if sys.platform == 'win32':
            await asyncio.sleep(0.5)
        else:
            await asyncio.sleep(0.3)
        
    except Exception as e:
        logger.debug(f"Error during safe_close: {type(e).__name__}")
    finally:
        connector = None


async def connect_to_mail(username: str, access_token: str, max_retries: int = 3):
    
    async with _imap_connection_lock:
        await asyncio.sleep(CONNECTION_DELAY)
        
        for attempt in range(1, max_retries + 1):
            imap_connector = None
            try:
                ssl_context = ssl.create_default_context()
                ssl_context.check_hostname = False
                ssl_context.verify_mode = ssl.CERT_NONE
                
                if sys.platform == 'win32':
                    timeout = min(IMAP_CONNECT_TIMEOUT, 30)
                else:
                    timeout = IMAP_CONNECT_TIMEOUT
                
                imap_connector = aioimaplib.IMAP4_SSL(
                    host=DEFAULT_IMAP_SERVER,
                    port=DEFAULT_IMAP_PORT,
                    ssl_context=ssl_context,
                    timeout=timeout
                )
                
                await asyncio.wait_for(imap_connector.wait_hello_from_server(), timeout=timeout)
                
                status, data = await asyncio.wait_for(
                    imap_connector.xoauth2(user=username, token=access_token),
                    timeout=timeout
                )
                
                if status != "OK":
                    await safe_close(imap_connector)
                    raise ConnectionError(f"Auth failed: {status}")
                
                logger.debug(f"‚úì IMAP connected for {username}")
                return imap_connector
                
            except socket.gaierror as e:
                if imap_connector:
                    await safe_close(imap_connector)
                logger.warning(f"DNS error connecting to IMAP for {username} (attempt {attempt}/{max_retries}): {e}")
                if attempt < max_retries:
                    await asyncio.sleep(5 * attempt)
                else:
                    raise ConnectionError(f"DNS resolution failed after {max_retries} attempts")
                    
            except (TimeoutError, asyncio.TimeoutError) as e:
                if imap_connector:
                    await safe_close(imap_connector)
                logger.warning(f"Timeout connecting to IMAP for {username} (attempt {attempt}/{max_retries})")
                if attempt < max_retries:
                    await asyncio.sleep(3 * attempt)
                else:
                    raise ConnectionError(f"Connection timeout after {max_retries} attempts")
            
            except aioimaplib.aioimaplib.Abort as e:
                if imap_connector:
                    await safe_close(imap_connector)
                logger.warning(f"IMAP protocol error for {username} (attempt {attempt}/{max_retries}): {e}")
                if attempt < max_retries:
                    await asyncio.sleep(4 * attempt)
                else:
                    raise ConnectionError(f"IMAP protocol error after {max_retries} attempts")
                    
            except ConnectionError as e:
                if imap_connector:
                    await safe_close(imap_connector)
                logger.warning(f"Connection error for {username} (attempt {attempt}/{max_retries}): {e}")
                if attempt < max_retries:
                    await asyncio.sleep(3 * attempt)
                else:
                    raise
                    
            except Exception as e:
                if imap_connector:
                    await safe_close(imap_connector)
                logger.warning(f"Error connecting to IMAP for {username} (attempt {attempt}/{max_retries}): {type(e).__name__}")
                logger.debug(f"Connection error details: {str(e)[:200]}")
                if attempt < max_retries:
                    await asyncio.sleep(2 * attempt)
                else:
                    raise ConnectionError(f"Connection failed: {type(e).__name__}")


async def delete(connector, message_ids: set[str], loop, username, access_token, folder_encoded, folder_decoded, client):
    """
    –ò—â–µ—Ç –∏ —É–¥–∞–ª—è–µ—Ç –≤—Å–µ –ø–∏—Å—å–º–∞ –∏–∑ —Å–ø–∏—Å–∫–∞ message_ids –≤ —É–∫–∞–∑–∞–Ω–Ω–æ–π –ø–∞–ø–∫–µ
    """
    global SEARCH_DATE_RANGE
    
    try:
        if SEARCH_DATE_RANGE:
            after_date, before_date = SEARCH_DATE_RANGE
            after_str = after_date.strftime("%d-%b-%Y")
            before_str = before_date.strftime("%d-%b-%Y")
            search_criteria = f'SINCE {after_str} BEFORE {before_str}'
        else:
            search_criteria = "ALL"
        
        try:
            status, messages = await asyncio.wait_for(
                connector.uid_search(search_criteria),
                timeout=IMAP_SEARCH_TIMEOUT
            )
        except Exception as e:
            logger.debug(f"Search error in '{folder_decoded}': {type(e).__name__}")
            return 0
        
        if status != "OK" or not messages or not messages[0]:
            return 0
        
        if isinstance(messages[0], bytes) and b'[UNAVAILABLE]' in messages[0]:
            return 0
        
        message_uids = messages[0].split()
        
        if not message_uids:
            logger.debug(f"No messages in date range in '{folder_decoded}'")
            return 0
        
        total = len(message_uids)
        logger.info(f"–ù–∞–π–¥–µ–Ω–æ {total} —Å–æ–æ–±—â–µ–Ω–∏–π –¥–ª—è –ø—Ä–æ–≤–µ—Ä–∫–∏ –≤ '{folder_decoded}'")
        
        MAX_TO_CHECK = 500000
        if total > MAX_TO_CHECK:
            logger.warning(f"–û–≥—Ä–∞–Ω–∏—á–µ–Ω–∏–µ –¥–æ {MAX_TO_CHECK} —Å–æ–æ–±—â–µ–Ω–∏–π")
            message_uids = message_uids[:MAX_TO_CHECK]
        
        # –°–æ–∑–¥–∞–µ–º –≤–∞—Ä–∏–∞–Ω—Ç—ã –ø–æ–∏—Å–∫–∞ –¥–ª—è –∫–∞–∂–¥–æ–≥–æ message_id
        search_variants = {}
        for msg_id in message_ids:
            rfc_clean = msg_id.strip('<>')
            search_variants[msg_id] = [
                rfc_clean.encode(),
                f"<{rfc_clean}>".encode(),
                f"Message-ID: {rfc_clean}".encode(),
                f"Message-ID: <{rfc_clean}>".encode(),
                f"Message-Id: {rfc_clean}".encode(),
                f"Message-Id: <{rfc_clean}>".encode(),
            ]
        
        CHUNK_SIZE = 500 
        PAUSE_BETWEEN_MESSAGES = 0.05 
        PAUSE_BETWEEN_CHUNKS = 1.0
        KEEPALIVE_INTERVAL = 50
        
        checked = 0
        failed_uids = []
        last_keepalive = 0
        deleted_count = 0
        
        # –ï—Å–ª–∏ –ø–∏—Å–µ–º –º–∞–ª–æ (< 1000), –Ω–µ –¥–µ–ª–∞–µ–º –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ –º–µ–∂–¥—É chunks
        use_reconnect = total > 1000
        
        for chunk_start in range(0, len(message_uids), CHUNK_SIZE):
            chunk_end = min(chunk_start + CHUNK_SIZE, len(message_uids))
            chunk = message_uids[chunk_start:chunk_end]
            
            chunk_num = chunk_start // CHUNK_SIZE + 1
            total_chunks = (len(message_uids) + CHUNK_SIZE - 1) // CHUNK_SIZE
            
            # –ü–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–∞–µ–º—Å—è —Ç–æ–ª—å–∫–æ –µ—Å–ª–∏ –º–Ω–æ–≥–æ –ø–∏—Å–µ–º –∏ —ç—Ç–æ –Ω–µ –ø–µ—Ä–≤—ã–π chunk
            if use_reconnect and chunk_num > 1:
                logger.info(f"üì¶ Chunk {chunk_num}/{total_chunks}: UIDs {chunk_start+1}-{chunk_end} in '{folder_decoded}'")
                logger.info(f"üîÑ Reconnecting for chunk {chunk_num}...")
                
                try:
                    await safe_close(connector)
                except:
                    pass
                
                await asyncio.sleep(2.0)
                
                cached_token = get_cached_token(username)
                if cached_token:
                    access_token = cached_token
                else:
                    try:
                        fresh_token = await loop.run_in_executor(None, client.user_token.get, username)
                        access_token = fresh_token.access_token
                        cache_token(username, access_token, fresh_token.expires_in)
                        logger.debug(f"‚úì Token refreshed for chunk {chunk_num}")
                    except Exception as e:
                        logger.debug(f"Token refresh failed: {e}")
                
                reconnect_attempts = 0
                max_reconnect_attempts = 3
                
                while reconnect_attempts < max_reconnect_attempts:
                    try:
                        connector = await connect_to_mail(username=username, access_token=access_token)
                        
                        status, _ = await asyncio.wait_for(
                            connector.select(folder_encoded),
                            timeout=IMAP_SELECT_TIMEOUT
                        )
                        
                        if status == "OK":
                            logger.info(f"‚úÖ Connected for chunk {chunk_num}")
                            break
                        else:
                            raise Exception(f"SELECT failed: {status}")
                        
                    except Exception as e:
                        reconnect_attempts += 1
                        logger.warning(f"Reconnect attempt {reconnect_attempts}/{max_reconnect_attempts} failed: {type(e).__name__}")
                        
                        if reconnect_attempts < max_reconnect_attempts:
                            await asyncio.sleep(3.0 * reconnect_attempts)
                        else:
                            logger.error(f"Failed to reconnect after {max_reconnect_attempts} attempts")
                            return deleted_count
            else:
                if total_chunks > 1:
                    logger.info(f"üì¶ Chunk {chunk_num}/{total_chunks}: UIDs {chunk_start+1}-{chunk_end}")
            
            for uid in chunk:
                try:
                    msg_uid = int(uid)
                except ValueError:
                    continue
                
                checked += 1
                
                if checked % 100 == 0:
                    logger.info(f"‚è≥ –ü—Ä–æ–≥—Ä–µ—Å—Å: {checked}/{len(message_uids)} —Å–æ–æ–±—â–µ–Ω–∏–π...")
                
                if checked - last_keepalive >= KEEPALIVE_INTERVAL:
                    await keepalive(connector)
                    last_keepalive = checked
                
                try:
                    status, data = await asyncio.wait_for(
                        connector.uid('fetch', msg_uid, "(BODY.PEEK[HEADER.FIELDS (MESSAGE-ID)])"),
                        timeout=15
                    )
                    
                    if status == "OK" and len(data) > 1:
                        headers = data[1]
                        
                        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –≤—Å–µ –≤–∞—Ä–∏–∞–Ω—Ç—ã –≤—Å–µ—Ö message_id
                        found_msg_id = None
                        for msg_id, variants in search_variants.items():
                            for variant in variants:
                                if variant in headers:
                                    found_msg_id = msg_id
                                    break
                            if found_msg_id:
                                break
                        
                        if found_msg_id:
                            logger.info(f"‚úÖ –ù–∞–π–¥–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–µ —Å UID {msg_uid} (msgId: {found_msg_id}) –≤ '{folder_decoded}'")
                            try:
                                await asyncio.wait_for(
                                    connector.uid('store', msg_uid, "+FLAGS", "\\Deleted"),
                                    timeout=15
                                )
                                await asyncio.wait_for(connector.expunge(), timeout=30)
                                
                                deleted_count += 1
                                
                                await loop.run_in_executor(
                                    None,
                                    write_deleted,
                                    username,
                                    folder_decoded,
                                    found_msg_id
                                )
                                
                            except Exception as e:
                                logger.error(f"–û—à–∏–±–∫–∞ —É–¥–∞–ª–µ–Ω–∏—è UID {msg_uid}: {e}")
                    
                    await asyncio.sleep(PAUSE_BETWEEN_MESSAGES)
                    
                except (TimeoutError, asyncio.TimeoutError, aioimaplib.aioimaplib.CommandTimeout):
                    logger.warning(f"‚è± Timeout on UID {msg_uid}")
                    failed_uids.append(msg_uid)
                    continue
                
                except aioimaplib.aioimaplib.Abort as e:
                    logger.warning(f"‚ö†Ô∏è  IMAP Abort on UID {msg_uid}: {str(e)[:100]}")
                    failed_uids.append(msg_uid)
                    continue
                    
                except Exception as e:
                    logger.warning(f"Error on UID {msg_uid}: {type(e).__name__}")
                    failed_uids.append(msg_uid)
                    continue
            
            if chunk_end < len(message_uids) and use_reconnect:
                logger.info(f"üí§ Resting {PAUSE_BETWEEN_CHUNKS}s...")
                await asyncio.sleep(PAUSE_BETWEEN_CHUNKS)
        
        if failed_uids:
            logger.warning(f"‚ö†Ô∏è  Failed UIDs: {len(failed_uids)}")
        
        if deleted_count == 0:
            logger.debug(f"–°–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö Message-ID –Ω–µ –Ω–∞–π–¥–µ–Ω–æ –≤ '{folder_decoded}' (–ø—Ä–æ–≤–µ—Ä–µ–Ω–æ {checked} —Å–æ–æ–±—â–µ–Ω–∏–π)")
        
        return deleted_count
        
    except Exception as e:
        logger.error(f"–û—à–∏–±–∫–∞ –≤ delete –¥–ª—è '{folder_decoded}': {type(e).__name__} - {e}")
        logger.debug(traceback.format_exc())
        return 0


async def get_user_token_async(client, recipient, loop, max_retries: int = 3):
    
    cached_token = get_cached_token(recipient)
    if cached_token:
        return cached_token
    
    for attempt in range(1, max_retries + 1):
        try:
            if attempt > 1:
                await asyncio.sleep(2 * attempt)
            
            user_token = await loop.run_in_executor(
                None, 
                client.user_token.get, 
                recipient
            )
            
            cache_token(recipient, user_token.access_token, user_token.expires_in)
            
            logger.debug(f"üîë Token obtained and cached for {recipient}")
            return user_token.access_token
            
        except ClientOAuthError as e:
            error_msg = f"OAuth error: {e}"
            logger.error(f"‚ùå Token request failed for {recipient} (attempt {attempt}/{max_retries}): {error_msg}")
            if attempt == max_retries:
                raise Exception(f"OAuth failed after {max_retries} attempts: {e}")
                
        except requests.exceptions.ConnectionError as e:
            error_msg = "Network/DNS error"
            logger.error(f"‚ùå Token request failed for {recipient} (attempt {attempt}/{max_retries}): {error_msg}")
            
            if attempt == max_retries:
                raise Exception(f"Network error after {max_retries} attempts")
            
            await asyncio.sleep(5 * attempt)
            
        except Exception as e:
            error_msg = f"{type(e).__name__}"
            logger.error(f"‚ùå Token request failed for {recipient} (attempt {attempt}/{max_retries}): {error_msg}")
            logger.debug(f"Token error details: {str(e)[:200]}")
            
            if attempt == max_retries:
                raise Exception(f"Token request failed: {type(e).__name__}")


async def process_recipient(recipient, message_ids, client, loop, semaphore, recipient_index, total_recipients):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –æ–¥–Ω–æ–≥–æ –ø–æ–ª—É—á–∞—Ç–µ–ª—è - –∏—â–µ—Ç –∏ —É–¥–∞–ª—è–µ—Ç –ø–∏—Å—å–º–∞ —Å —É–∫–∞–∑–∞–Ω–Ω—ã–º–∏ message_ids
    """
    
    await asyncio.sleep(RECIPIENT_DELAY * (recipient_index % MAX_CONCURRENT_IMAP))
    
    async with semaphore:
        logger.info(f"üöÄ [{recipient_index + 1}/{total_recipients}] Starting processing for {recipient}")
        logger.info(f"   üìß –ü–∏—Å–µ–º –∫ —É–¥–∞–ª–µ–Ω–∏—é –¥–ª—è —ç—Ç–æ–≥–æ –ø–æ–ª—É—á–∞—Ç–µ–ª—è: {len(message_ids)}")
        
        if recipient_index % GC_INTERVAL == 0:
            force_cleanup()
        
        connector = None
        try:
            try:
                access_token = await get_user_token_async(client, recipient, loop)
            except Exception as e:
                error_type = type(e).__name__
                error_msg = str(e)[:200]
                logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–ª—É—á–∏—Ç—å —Ç–æ–∫–µ–Ω –¥–ª—è {recipient}: {error_type} - {error_msg}")
                await loop.run_in_executor(
                    None,
                    write_failed_recipient,
                    recipient,
                    f"Token error: {error_type}",
                    len(message_ids)
                )
                add_deletion_stats(0, has_error=True)
                return
            
            try:
                connector = await connect_to_mail(username=recipient, access_token=access_token)
                
                if connector.protocol.state != "AUTH":
                    raise ConnectionError("Not authenticated")
                
                logger.info(f"üîå Connected to {recipient}")
                
                status, folders_response = await asyncio.wait_for(
                    connector.list('""', "*"),
                    timeout=IMAP_LIST_TIMEOUT
                )
                
                logger.info(f"üìã LIST command status: {status}, received {len(folders_response)} lines")
                
            except (TimeoutError, asyncio.TimeoutError) as e:
                error_msg = "–¢–∞–π–º–∞—É—Ç –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è/LIST"
                logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ {recipient}: {error_msg}")
                await loop.run_in_executor(
                    None,
                    write_failed_recipient,
                    recipient,
                    "Connection timeout",
                    len(message_ids)
                )
                if connector:
                    await safe_close(connector)
                add_deletion_stats(0, has_error=True)
                return
                
            except ConnectionError as e:
                error_msg = f"–û—à–∏–±–∫–∞ –ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è: {str(e)[:100]}"
                logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ {recipient}: {error_msg}")
                await loop.run_in_executor(
                    None,
                    write_failed_recipient,
                    recipient,
                    f"Connection error: {str(e)[:100]}",
                    len(message_ids)
                )
                if connector:
                    await safe_close(connector)
                add_deletion_stats(0, has_error=True)
                return
                
            except socket.gaierror as e:
                error_msg = "–û—à–∏–±–∫–∞ DNS"
                logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ {recipient}: {error_msg}")
                await loop.run_in_executor(
                    None,
                    write_failed_recipient,
                    recipient,
                    "DNS error",
                    len(message_ids)
                )
                if connector:
                    await safe_close(connector)
                add_deletion_stats(0, has_error=True)
                return
                
            except Exception as e:
                error_type = type(e).__name__
                error_msg = f"{error_type}: {str(e)[:100]}"
                logger.error(f"‚ùå –ù–µ —É–¥–∞–ª–æ—Å—å –ø–æ–¥–∫–ª—é—á–∏—Ç—å—Å—è –∫ {recipient}: {error_msg}")
                logger.debug(traceback.format_exc())
                await loop.run_in_executor(
                    None,
                    write_failed_recipient,
                    recipient,
                    f"Unexpected: {error_type}",
                    len(message_ids)
                )
                if connector:
                    await safe_close(connector)
                add_deletion_stats(0, has_error=True)
                return
            
            folders = []
            i = 0
            
            while i < len(folders_response):
                folder_line = folders_response[i]
                
                if folder_line == b"LIST Completed.":
                    i += 1
                    continue
                
                if isinstance(folder_line, bytearray):
                    if i > 0:
                        prev_line = folders_response[i - 1]
                        if isinstance(prev_line, bytes):
                            prev_decoded = prev_line.decode('utf-8', errors='replace')
                            if not re.search(r'\{(\d+)\}\s*$', prev_decoded):
                                i += 1
                                continue
                        else:
                            i += 1
                            continue
                    else:
                        i += 1
                        continue
                
                if not isinstance(folder_line, bytes):
                    i += 1
                    continue
                
                try:
                    decoded = folder_line.decode('utf-8', errors='replace')
                except:
                    i += 1
                    continue
                
                if '\\Noselect' in decoded:
                    i += 1
                    continue
                
                literal_match = re.search(r'\{(\d+)\}\s*$', decoded)
                
                if literal_match:
                    if i + 1 < len(folders_response):
                        next_line = folders_response[i + 1]
                        
                        if isinstance(next_line, bytearray):
                            try:
                                folder_name_raw = next_line.decode('utf-8', errors='replace')
                                folder_name_decoded = decode_modified_utf7(folder_name_raw)
                                folder_name_escaped = escape_imap_folder_name(folder_name_raw)
                                
                                folders.append((f'"{folder_name_escaped}"', folder_name_decoded))
                                logger.debug(f"[{i}+{i+1}] ‚úì PARSED literal: '{folder_name_decoded}'")
                                
                                i += 2
                                continue
                                
                            except Exception as e:
                                logger.debug(f"[{i+1}] Failed to process literal continuation: {e}")
                                i += 2
                                continue
                        else:
                            logger.debug(f"[{i+1}] Expected bytearray after literal header")
                            i += 1
                            continue
                    else:
                        logger.debug(f"[{i}] Literal header at end of list")
                        i += 1
                        continue
                
                parsed = map_folder(folder_line)
                if parsed:
                    folder_encoded, folder_decoded = parsed
                    folders.append(parsed)
                    logger.debug(f"[{i}] ‚úì PARSED: '{folder_decoded}'")
                
                i += 1
            
            logger.info(f"üìÅ Total parsed folders: {len(folders)} for {recipient}")
            
            if not folders:
                logger.warning(f"‚ö†Ô∏è  No folders found for {recipient}")
                if connector:
                    await safe_close(connector)
                return
            
            priority_folders = []
            other_folders = []
            
            priority_keywords = ['inbox', 'sent', 'drafts', '–æ—Ç–ø—Ä–∞–≤–ª–µ–Ω–Ω—ã–µ', '—á–µ—Ä–Ω–æ–≤–∏–∫–∏', '–≤—Ö–æ–¥—è—â–∏–µ', 'spam', 'junk']
            
            for folder_encoded, folder_decoded in folders:
                folder_lower = folder_decoded.lower()
                is_priority = any(keyword in folder_lower for keyword in priority_keywords)
                
                if is_priority:
                    priority_folders.append((folder_encoded, folder_decoded))
                else:
                    other_folders.append((folder_encoded, folder_decoded))
            
            total_deleted = 0
            total_checked_folders = 0
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω—ã–µ –ø–∞–ø–∫–∏ —Å –û–î–ù–ò–ú —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ–º
            for folder_encoded, folder_decoded in priority_folders:
                logger.info(f"üìÇ [{recipient}] –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø—Ä–∏–æ—Ä–∏—Ç–µ—Ç–Ω–æ–π –ø–∞–ø–∫–∏: {folder_decoded}")
                total_checked_folders += 1
                
                try:
                    # –ò—Å–ø–æ–ª—å–∑—É–µ–º SELECT –≤–º–µ—Å—Ç–æ –ø–µ—Ä–µ–ø–æ–¥–∫–ª—é—á–µ–Ω–∏—è
                    status, _ = await asyncio.wait_for(
                        connector.select(folder_encoded),
                        timeout=IMAP_SELECT_TIMEOUT
                    )
                    
                    if status != "OK":
                        logger.debug(f"Cannot select folder '{folder_decoded}': {status}")
                        continue
                    
                    logger.info(f"üìÇ –û–±—Ä–∞–±–æ—Ç–∫–∞ '{folder_decoded}'")
                    
                    count = await delete(
                        connector=connector,
                        message_ids=message_ids,
                        loop=loop,
                        username=recipient,
                        access_token=access_token,
                        folder_encoded=folder_encoded,
                        folder_decoded=folder_decoded,
                        client=client
                    )
                    
                    total_deleted += count
                    
                    if count > 0:
                        logger.info(f"‚úÖ –£–¥–∞–ª–µ–Ω–æ {count} —Å–æ–æ–±—â–µ–Ω–∏–µ(–π) –∏–∑ '{folder_decoded}'")
                    
                except Exception as e:
                    error_type = type(e).__name__
                    logger.warning(f"‚ö†Ô∏è  Error processing '{folder_decoded}': {error_type}")
                    logger.debug(f"Full error: {str(e)[:200]}")
                    continue
            
            # –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ–º –æ—Å—Ç–∞–ª—å–Ω—ã–µ –ø–∞–ø–∫–∏ —Å –¢–ï–ú –ñ–ï —Å–æ–µ–¥–∏–Ω–µ–Ω–∏–µ–º
            for folder_encoded, folder_decoded in other_folders:
                logger.info(f"üìÇ [{recipient}] –û–±—Ä–∞–±–æ—Ç–∫–∞: {folder_decoded}")
                total_checked_folders += 1
                
                try:
                    status, _ = await asyncio.wait_for(
                        connector.select(folder_encoded),
                        timeout=IMAP_SELECT_TIMEOUT
                    )
                    
                    if status != "OK":
                        logger.debug(f"Cannot select folder '{folder_decoded}': {status}")
                        continue
                    
                    logger.info(f"üìÇ –û–±—Ä–∞–±–æ—Ç–∫–∞ '{folder_decoded}'")
                    
                    count = await delete(
                        connector=connector,
                        message_ids=message_ids,
                        loop=loop,
                        username=recipient,
                        access_token=access_token,
                        folder_encoded=folder_encoded,
                        folder_decoded=folder_decoded,
                        client=client
                    )
                    
                    total_deleted += count
                    
                    if count > 0:
                        logger.info(f"‚úÖ –£–¥–∞–ª–µ–Ω–æ {count} —Å–æ–æ–±—â–µ–Ω–∏–µ(–π) –∏–∑ '{folder_decoded}'")
                    
                except Exception as e:
                    error_type = type(e).__name__
                    logger.warning(f"‚ö†Ô∏è  Error processing '{folder_decoded}': {error_type}")
                    logger.debug(f"Full error: {str(e)[:200]}")
                    continue
            
            if total_deleted > 0:
                logger.info(f"‚úÖ [{recipient}] Total deleted: {total_deleted} message(s) from {total_checked_folders} folder(s)")
            else:
                logger.info(f"‚ÑπÔ∏è  [{recipient}] No messages found (checked {total_checked_folders} folder(s)). Messages may have been already deleted or were not delivered to this recipient.")
            
            # –û–±–Ω–æ–≤–ª—è–µ–º –≥–ª–æ–±–∞–ª—å–Ω—É—é —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫—É
            add_deletion_stats(total_deleted)
        
        except Exception as e:
            error_type = type(e).__name__
            error_msg = f"{error_type}: {str(e)[:200]}"
            logger.error(f"‚ùå –ù–µ–æ–∂–∏–¥–∞–Ω–Ω–∞—è –æ—à–∏–±–∫–∞ –ø—Ä–∏ –æ–±—Ä–∞–±–æ—Ç–∫–µ {recipient}: {error_msg}")
            logger.debug(traceback.format_exc())
            
            await loop.run_in_executor(
                None,
                write_failed_recipient,
                recipient,
                f"Unexpected error: {error_type}",
                len(message_ids)
            )
            add_deletion_stats(0, has_error=True)
        finally:
            if connector:
                await safe_close(connector)
            force_cleanup()


async def process_recipients_batch(client, recipient_messages, loop, semaphore, batch_offset):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–∞–∫–µ—Ç –ø–æ–ª—É—á–∞—Ç–µ–ª–µ–π
    recipient_messages: dict {recipient: set(message_ids)}
    """
    tasks = []
    recipients = list(recipient_messages.keys())
    total_recipients = len(recipients)
    
    for idx, recipient in enumerate(recipients):
        message_ids = recipient_messages[recipient]
        task = asyncio.create_task(
            process_recipient(
                recipient, 
                message_ids, 
                client, 
                loop, 
                semaphore,
                batch_offset + idx,
                batch_offset + total_recipients
            )
        )
        tasks.append(task)
    
    if tasks:
        results = await asyncio.gather(*tasks, return_exceptions=True)
        
        successful = sum(1 for r in results if not isinstance(r, Exception))
        failed = sum(1 for r in results if isinstance(r, Exception))
        
        for idx, result in enumerate(results):
            if isinstance(result, Exception):
                logger.error(f"‚ùå Task exception for {recipients[idx]}: {type(result).__name__} - {result}")
        
        return successful, failed
    return 0, 0


async def process_recipients_in_batches(client, recipient_messages):
    """
    –û–±—Ä–∞–±–∞—Ç—ã–≤–∞–µ—Ç –ø–æ–ª—É—á–∞—Ç–µ–ª–µ–π –ø–∞–∫–µ—Ç–∞–º–∏
    recipient_messages: dict {recipient: set(message_ids)}
    """
    loop = asyncio.get_running_loop()
    
    def exception_handler(loop, context):
        exception = context.get('exception')
        
        if isinstance(exception, aioimaplib.aioimaplib.CommandTimeout):
            logger.debug("Suppressed CommandTimeout exception in task")
            return
        
        if isinstance(exception, aioimaplib.aioimaplib.Abort):
            logger.debug(f"Suppressed Abort exception: {exception}")
            return
        
        if isinstance(exception, socket.gaierror):
            logger.error(f"‚ö†Ô∏è  DNS Error (gaierror): {exception}")
            logger.error(f"   This usually means too many simultaneous connections")
            logger.error(f"   The script will continue with other recipients")
            return
        
        if sys.platform == 'win32' and 'Task was destroyed but it is pending' in str(context.get('message', '')):
            logger.debug("Suppressed 'Task destroyed' warning on Windows")
            return
        
        message = context.get('message', 'No message')
        logger.error(f"‚ö†Ô∏è  Exception in async task: {message}")
        if exception:
            logger.error(f"   Exception type: {type(exception).__name__}")
            logger.error(f"   Exception details: {exception}")
    
    loop.set_exception_handler(exception_handler)
    
    semaphore = asyncio.Semaphore(MAX_CONCURRENT_IMAP)
    
    recipients = list(recipient_messages.keys())
    total_recipients = len(recipients)
    total_batches = (total_recipients + BATCH_SIZE - 1) // BATCH_SIZE
    
    logger.info(f"üöÄ –û–±—Ä–∞–±–æ—Ç–∫–∞ {total_recipients} –ø–æ–ª—É—á–∞—Ç–µ–ª–µ–π –≤ {total_batches} –ø–∞–∫–µ—Ç–∞—Ö")
    logger.info(f"   –†–∞–∑–º–µ—Ä –ø–∞–∫–µ—Ç–∞: {BATCH_SIZE}")
    logger.info(f"   –ü–∞—É–∑–∞ –º–µ–∂–¥—É –ø–∞–∫–µ—Ç–∞–º–∏: {BATCH_PAUSE}—Å")
    logger.info(f"   –ú–∞–∫—Å–∏–º—É–º –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω—ã—Ö IMAP: {MAX_CONCURRENT_IMAP}")
    
    total_successful = 0
    total_failed = 0
    
    for batch_num in range(total_batches):
        batch_start = batch_num * BATCH_SIZE
        batch_end = min(batch_start + BATCH_SIZE, total_recipients)
        batch_recipients = recipients[batch_start:batch_end]
        
        # –°–æ–∑–¥–∞–µ–º –ø–æ–¥—Å–ª–æ–≤–∞—Ä—å –¥–ª—è —ç—Ç–æ–≥–æ –ø–∞–∫–µ—Ç–∞
        batch_recipient_messages = {r: recipient_messages[r] for r in batch_recipients}
        
        logger.info(f"")
        logger.info(f"{'='*80}")
        logger.info(f"üì¶ –ü–ê–ö–ï–¢ {batch_num + 1}/{total_batches}: –û–±—Ä–∞–±–æ—Ç–∫–∞ –ø–æ–ª—É—á–∞—Ç–µ–ª–µ–π {batch_start + 1}-{batch_end}")
        logger.info(f"{'='*80}")
        
        batch_start_time = time.time()
        
        successful, failed = await process_recipients_batch(
            client, batch_recipient_messages, loop, semaphore, batch_start
        )
        
        total_successful += successful
        total_failed += failed
        
        batch_duration = time.time() - batch_start_time
        
        logger.info(f"")
        logger.info(f"üìä –ü–∞–∫–µ—Ç {batch_num + 1} –∑–∞–≤–µ—Ä—à–µ–Ω:")
        logger.info(f"   ‚úÖ –£—Å–ø–µ—à–Ω–æ: {successful}")
        logger.info(f"   ‚ùå –û—à–∏–±–æ–∫: {failed}")
        logger.info(f"   ‚è±Ô∏è  –î–ª–∏—Ç–µ–ª—å–Ω–æ—Å—Ç—å: {batch_duration:.1f}—Å")
        logger.info(f"   üìà –û–±—â–∏–π –ø—Ä–æ–≥—Ä–µ—Å—Å: {batch_end}/{total_recipients} ({100*batch_end//total_recipients}%)")
        
        force_cleanup()
        
        if batch_end < total_recipients:
            logger.info(f"üí§ –ü–∞—É–∑–∞ {BATCH_PAUSE}—Å –ø–µ—Ä–µ–¥ —Å–ª–µ–¥—É—é—â–∏–º –ø–∞–∫–µ—Ç–æ–º...")
            await asyncio.sleep(BATCH_PAUSE)
    
    logger.info(f"")
    logger.info(f"{'='*80}")
    logger.info(f"üìä –ò–¢–û–ì–û–í–ê–Ø –°–¢–ê–¢–ò–°–¢–ò–ö–ê")
    logger.info(f"{'='*80}")
    logger.info(f"   –í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ: {total_recipients}")
    logger.info(f"   ‚úÖ –£—Å–ø–µ—à–Ω–æ: {total_successful}")
    logger.info(f"   ‚ùå –û—à–∏–±–æ–∫: {total_failed}")
    
    # –í—ã–≤–æ–¥ —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏ —É–¥–∞–ª–µ–Ω–∏—è
    stats = get_deletion_stats()
    logger.info(f"")
    logger.info(f"{'='*80}")
    logger.info(f"üìß –°–¢–ê–¢–ò–°–¢–ò–ö–ê –£–î–ê–õ–ï–ù–ò–Ø")
    logger.info(f"{'='*80}")
    logger.info(f"   üóëÔ∏è  –í—Å–µ–≥–æ —É–¥–∞–ª–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π: {stats['total_deleted']}")
    logger.info(f"   ‚úÖ –ü–æ–ª—É—á–∞—Ç–µ–ª–µ–π —Å —É–¥–∞–ª–µ–Ω–∏—è–º–∏: {stats['recipients_with_deletions']}")
    logger.info(f"   ‚ÑπÔ∏è  –ü–æ–ª—É—á–∞—Ç–µ–ª–µ–π –±–µ–∑ —É–¥–∞–ª–µ–Ω–∏–π: {stats['recipients_without_deletions']}")
    logger.info(f"   ‚ùå –ü–æ–ª—É—á–∞—Ç–µ–ª–µ–π —Å –æ—à–∏–±–∫–∞–º–∏: {stats['recipients_with_errors']}")
    
    if stats['recipients_with_errors'] > 0:
        logger.info(f"")
        logger.info(f"‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: {stats['recipients_with_errors']} –ø–æ–ª—É—á–∞—Ç–µ–ª—è(–µ–π) –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å!")
        logger.info(f"   –°–ø–∏—Å–æ–∫ –Ω–µ–æ–±—Ä–∞–±–æ—Ç–∞–Ω–Ω—ã—Ö –ø–æ–ª—É—á–∞—Ç–µ–ª–µ–π —Å–æ—Ö—Ä–∞–Ω–µ–Ω –≤: {FAILED_RECIPIENTS_FILE}")
        logger.info(f"   –í–æ–∑–º–æ–∂–Ω—ã–µ –ø—Ä–∏—á–∏–Ω—ã:")
        logger.info(f"   - –£ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –æ—Ç–∫–ª—é—á–µ–Ω –¥–æ—Å—Ç—É–ø –ø–æ IMAP")
        logger.info(f"   - –°–µ—Ä–≤–∏—Å–Ω–æ–µ –ø—Ä–∏–ª–æ–∂–µ–Ω–∏–µ –Ω–µ –∏–º–µ–µ—Ç –ø—Ä–∞–≤ –¥–ª—è –ø–æ–ª—É—á–µ–Ω–∏—è —Ç–æ–∫–µ–Ω–∞ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è")
        logger.info(f"   - –£ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è –∑–∞–±–ª–æ–∫–∏—Ä–æ–≤–∞–Ω –∞–∫–∫–∞—É–Ω—Ç")
        logger.info(f"   - –ü—Ä–æ–±–ª–µ–º—ã —Å —Å–µ—Ç–µ–≤—ã–º –ø–æ–¥–∫–ª—é—á–µ–Ω–∏–µ–º")
    
    if stats['recipients_without_deletions'] > 0:
        logger.info(f"")
        logger.info(f"üí° –ü—Ä–∏–º–µ—á–∞–Ω–∏–µ: –£ {stats['recipients_without_deletions']} –ø–æ–ª—É—á–∞—Ç–µ–ª—è(–µ–π) –Ω–µ –Ω–∞–π–¥–µ–Ω–æ —Å–æ–æ–±—â–µ–Ω–∏–π, —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤—É—é—â–∏—Ö –∫—Ä–∏—Ç–µ—Ä–∏—è–º.")
        logger.info(f"   –≠—Ç–æ –º–æ–∂–µ—Ç –æ–∑–Ω–∞—á–∞—Ç—å:")
        logger.info(f"   - –°–æ–æ–±—â–µ–Ω–∏—è —É–∂–µ –±—ã–ª–∏ —É–¥–∞–ª–µ–Ω—ã")
        logger.info(f"   - –°–æ–æ–±—â–µ–Ω–∏—è –Ω–µ –±—ã–ª–∏ –¥–æ—Å—Ç–∞–≤–ª–µ–Ω—ã —ç—Ç–∏–º –ø–æ–ª—É—á–∞—Ç–µ–ª—è–º")
        logger.info(f"   - –°–æ–æ–±—â–µ–Ω–∏—è –Ω–µ –ø–æ–ø–∞–¥–∞—é—Ç –≤ —É–∫–∞–∑–∞–Ω–Ω—ã–π –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω")


def write_deleted(user: str, folder: str, message_id: str = ""):
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    with open(DELETED_MESSAGES_FILE, "a", encoding='utf-8') as file:
        if message_id:
            file.write(f"{timestamp} | {user} | Folder: {folder} | MsgID: {message_id}\n")
        else:
            file.write(f"{timestamp} | {user} | Folder: {folder}\n")
    logger.info(f"‚úÖ Logged deletion: {user} - {folder}")


def write_failed_recipient(user: str, reason: str, message_ids_count: int):
    """–õ–æ–≥–∏—Ä–æ–≤–∞–Ω–∏–µ –ø–æ–ª—É—á–∞—Ç–µ–ª–µ–π, –∫–æ—Ç–æ—Ä—ã—Ö –Ω–µ —É–¥–∞–ª–æ—Å—å –æ–±—Ä–∞–±–æ—Ç–∞—Ç—å"""
    timestamp = datetime.now().strftime('%Y-%m-%d %H:%M:%S')
    with open(FAILED_RECIPIENTS_FILE, "a", encoding='utf-8') as file:
        file.write(f"{timestamp} | {user} | Reason: {reason} | Messages to delete: {message_ids_count}\n")
    logger.debug(f"üìù Logged failed recipient: {user} - {reason}")


def get_settings():
    # –í—Å—Ç–∞–≤—å—Ç–µ —Å–≤–æ–∏ –¥–∞–Ω–Ω—ã–µ
    HARDCODED_TOKEN = ""
    HARDCODED_ORG_ID = ""
    HARDCODED_CLIENT_ID = ""
    HARDCODED_CLIENT_SECRET = ""
    
    settings = SettingParams(
        oauth_token=environ.get(OAUTH_TOKEN_ARG, HARDCODED_TOKEN),
        organization_id=int(environ.get(ORGANIZATION_ID_ARG, HARDCODED_ORG_ID)),
        app_client_id=environ.get(APPLICATION_CLIENT_ID_ARG, HARDCODED_CLIENT_ID),
        app_client_secret=environ.get(APPLICATION_CLIENT_SECRET_ARG, HARDCODED_CLIENT_SECRET),
    )
    return settings


def fetch_audit_logs(
    client: "Client360", 
    sender_email: str,
    datetime_from: datetime,
    datetime_to: datetime,
    datetime_from_moscow: datetime,
    datetime_to_moscow: datetime,
    after_date: str, 
    before_date: str
) -> "FetchedMessages":
    """
    –ü–æ–ª—É—á–∞–µ—Ç –∏–∑ –∞—É–¥–∏—Ç-–ª–æ–≥–æ–≤ –≤—Å–µ –ø–∏—Å—å–º–∞ –æ—Ç —É–∫–∞–∑–∞–Ω–Ω–æ–≥–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è –∑–∞ —É–∫–∞–∑–∞–Ω–Ω—ã–π –ø–µ—Ä–∏–æ–¥
    –¢–µ–ø–µ—Ä—å —Å–æ—Ö—Ä–∞–Ω—è–µ—Ç —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø–æ–ª—É—á–∞—Ç–µ–ª—å -> —Å–ø–∏—Å–æ–∫ message_ids
    """
    
    logger.info("–ü–æ–∏—Å–∫ –≤ –∞—É–¥–∏—Ç-–ª–æ–≥–∞—Ö...")
    logger.info(f"–§–∏–ª—å—Ç—Ä –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è: {sender_email}")
    logger.info(f"–î–∞—Ç–∞: {datetime_from_moscow.strftime('%d-%m-%Y')}")
    logger.info(f"–î–∏–∞–ø–∞–∑–æ–Ω –≤—Ä–µ–º–µ–Ω–∏ (–ú–æ—Å–∫–≤–∞ UTC+3): {datetime_from_moscow.strftime('%H:%M:%S')} –¥–æ {datetime_to_moscow.strftime('%H:%M:%S')}")
    logger.info(f"–î–∏–∞–ø–∞–∑–æ–Ω DateTime (UTC): {datetime_from.strftime('%d-%m-%Y %H:%M:%S')} –¥–æ {datetime_to.strftime('%d-%m-%Y %H:%M:%S')}")
    logger.info(f"–î–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç API: {after_date} –¥–æ {before_date}")
    
    fetched_messages = FetchedMessages(
        recipient_messages=defaultdict(set),  # recipient -> set of message_ids
        all_message_ids=set(),
        subjects=set()
    )
    
    page_number = 1
    total_events_processed = 0
    matching_events = 0
    filtered_by_sender = 0
    filtered_by_time = 0
    sum_matching_prev = 0
    
    # –î–ª—è –¥–∏–∞–≥–Ω–æ—Å—Ç–∏–∫–∏ - —Å–æ–±–∏—Ä–∞–µ–º —É–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª–µ–π
    found_senders = set()
    
    # –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ–º –ø–µ—Ä–≤—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É —Å –º–∞–∫—Å–∏–º–∞–ª—å–Ω—ã–º —Ä–∞–∑–º–µ—Ä–æ–º
    audit_log = client.audit_log.get(
        after_date=after_date, 
        before_date=before_date,
    )
    
    # –ù–æ—Ä–º–∞–ª–∏–∑—É–µ–º email –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è –¥–ª—è —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
    sender_normalized = sender_email.lower().strip()
    
    while True:
        logger.info(f"")
        logger.info(f"üìÑ –°—Ç—Ä–∞–Ω–∏—Ü–∞ {page_number}: –ø–æ–ª—É—á–µ–Ω–æ {len(audit_log.events)} —Å–æ–±—ã—Ç–∏–π")
        
        for event in audit_log.events:
            total_events_processed += 1
            
            # –ò–∑–≤–ª–µ–∫–∞–µ–º email –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è –∏–∑ –ø–æ–ª—è from_
            event_from = event.from_.lower().strip() if event.from_ else ""
            
            # –ï—Å–ª–∏ –≤ –ø–æ–ª–µ from_ —Å–æ–¥–µ—Ä–∂–∏—Ç—Å—è –∏–º—è –∏ email –≤ —Ñ–æ—Ä–º–∞—Ç–µ "Name <email>", –∏–∑–≤–ª–µ–∫–∞–µ–º —Ç–æ–ª—å–∫–æ email
            from_emails = extract_emails(event.from_) if event.from_ else []
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º —Å–æ–≤–ø–∞–¥–µ–Ω–∏–µ –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è
            sender_match = False
            if sender_normalized in event_from:
                sender_match = True
            else:
                for email in from_emails:
                    if email.lower().strip() == sender_normalized:
                        sender_match = True
                        break
            
            if not sender_match:
                filtered_by_sender += 1
                continue
            
            # –ü—Ä–æ–≤–µ—Ä—è–µ–º –ø–æ–ø–∞–¥–∞–Ω–∏–µ –≤ –¥–∏–∞–ø–∞–∑–æ–Ω –¥–∞—Ç –∏ –≤—Ä–µ–º–µ–Ω–∏
            event_datetime = event.date
            
            # –£–±–∏—Ä–∞–µ–º timezone info –∏–∑ event_datetime –¥–ª—è –∫–æ—Ä—Ä–µ–∫—Ç–Ω–æ–≥–æ —Å—Ä–∞–≤–Ω–µ–Ω–∏—è
            if event_datetime.tzinfo is not None:
                event_datetime = event_datetime.replace(tzinfo=None)
            
            # –°—Ä–∞–≤–Ω–∏–≤–∞–µ–º UTC —Å UTC
            if event_datetime < datetime_from or event_datetime > datetime_to:
                filtered_by_time += 1
                continue
            
            # –°–æ–±—ã—Ç–∏–µ –ø–æ–¥—Ö–æ–¥–∏—Ç –ø–æ–¥ –∫—Ä–∏—Ç–µ—Ä–∏–∏
            matching_events += 1
            
            # ===== –ö–õ–Æ–ß–ï–í–û–ï –ò–ó–ú–ï–ù–ï–ù–ò–ï: —Å–æ—Ö—Ä–∞–Ω—è–µ–º —Å–æ–æ—Ç–≤–µ—Ç—Å—Ç–≤–∏–µ –ø–æ–ª—É—á–∞—Ç–µ–ª—å -> message_id =====
            recipient = event.userLogin
            msg_id = event.msgId
            
            # –î–æ–±–∞–≤–ª—è–µ–º message_id –¥–ª—è —ç—Ç–æ–≥–æ –ø–æ–ª—É—á–∞—Ç–µ–ª—è
            fetched_messages.recipient_messages[recipient].add(msg_id)
            
            # –î–æ–±–∞–≤–ª—è–µ–º –≤ –æ–±—â–∏–π –Ω–∞–±–æ—Ä message_id
            fetched_messages.all_message_ids.add(msg_id)
            
            # –î–æ–±–∞–≤–ª—è–µ–º —Ç–µ–º—É
            if event.subject:
                fetched_messages.subjects.add(event.subject)
        
        # –ü—Ä–æ–º–µ–∂—É—Ç–æ—á–Ω–∞—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ—Å–ª–µ –æ–±—Ä–∞–±–æ—Ç–∫–∏ —Å—Ç—Ä–∞–Ω–∏—Ü—ã
        page_matching = matching_events - sum_matching_prev
        logger.info(f"   –í—Å–µ–≥–æ —Å–æ–±—ã—Ç–∏–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {len(audit_log.events)}")
        logger.info(f"   –ü–æ–¥—Ö–æ–¥—è—â–∏—Ö —Å–æ–±—ã—Ç–∏–π –Ω–∞ —Å—Ç—Ä–∞–Ω–∏—Ü–µ: {page_matching}")
        logger.info(f"   –í—Å–µ–≥–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Å–æ–±—ã—Ç–∏–π: {matching_events}")
        sum_matching_prev = matching_events
        
        # –ü—Ä–æ–≤–µ—Ä—è–µ–º –µ—Å—Ç—å –ª–∏ —Å–ª–µ–¥—É—é—â–∞—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞
        logger.debug(f"   nextPageToken type: {type(audit_log.nextPageToken)}, value: '{audit_log.nextPageToken}'")
        has_next = audit_log.nextPageToken and audit_log.nextPageToken != ""
        
        # –ï—Å–ª–∏ –ø–æ–ª—É—á–∏–ª–∏ –ø–æ–ª–Ω—É—é —Å—Ç—Ä–∞–Ω–∏—Ü—É (100 —Å–æ–±—ã—Ç–∏–π) –Ω–æ –Ω–µ—Ç nextPageToken - —ç—Ç–æ –ø–æ–¥–æ–∑—Ä–∏—Ç–µ–ª—å–Ω–æ
        if len(audit_log.events) == 100 and not has_next:
            logger.warning(f"‚ö†Ô∏è  –í–ù–ò–ú–ê–ù–ò–ï: –ü–æ–ª—É—á–µ–Ω–æ –º–∞–∫—Å–∏–º–∞–ª—å–Ω–æ–µ –∫–æ–ª–∏—á–µ—Å—Ç–≤–æ —Å–æ–±—ã—Ç–∏–π (100), –Ω–æ nextPageToken –ø—É—Å—Ç–æ–π!")
            logger.warning(f"   –í–æ–∑–º–æ–∂–Ω–æ API –Ω–µ –≤–æ–∑–≤—Ä–∞—â–∞–µ—Ç –≤—Å–µ —Å–æ–±—ã—Ç–∏—è. –ü–æ–ø—Ä–æ–±—É–π—Ç–µ —É–º–µ–Ω—å—à–∏—Ç—å –≤—Ä–µ–º–µ–Ω–Ω–æ–π –¥–∏–∞–ø–∞–∑–æ–Ω.")
        
        if not has_next:
            logger.info(f"")
            logger.info(f"‚úì –î–æ—Å—Ç–∏–≥–Ω—É—Ç–∞ –ø–æ—Å–ª–µ–¥–Ω—è—è —Å—Ç—Ä–∞–Ω–∏—Ü–∞ –∞—É–¥–∏—Ç-–ª–æ–≥–∞ (nextPageToken: '{audit_log.nextPageToken}')")
            break
        
        logger.info(f"")
        logger.info(f"‚Üí –ü–µ—Ä–µ—Ö–æ–¥ –∫ —Å–ª–µ–¥—É—é—â–µ–π —Å—Ç—Ä–∞–Ω–∏—Ü–µ (nextPageToken: {audit_log.nextPageToken[:50]}...)")
        page_number += 1
        
        audit_log = client.audit_log.get(
            after_date=after_date,
            before_date=before_date,
            page_token=audit_log.nextPageToken,
        )
    
    logger.info(f"–í—Å–µ–≥–æ –æ–±—Ä–∞–±–æ—Ç–∞–Ω–æ —Å—Ç—Ä–∞–Ω–∏—Ü: {page_number}")
    logger.info(f"–í—Å–µ–≥–æ –ø—Ä–æ—Å–∫–∞–Ω–∏—Ä–æ–≤–∞–Ω–æ —Å–æ–±—ã—Ç–∏–π: {total_events_processed}")
    logger.info(f"–ù–∞–π–¥–µ–Ω–æ –ø–æ–¥—Ö–æ–¥—è—â–∏—Ö —Å–æ–±—ã—Ç–∏–π: {matching_events}")
    logger.info(f"–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –ø–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—é: {filtered_by_sender}")
    logger.info(f"–û—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –ø–æ –≤—Ä–µ–º–µ–Ω–∏: {filtered_by_time}")
    logger.info(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö message ID: {len(fetched_messages.all_message_ids)}")
    logger.info(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö –ø–æ–ª—É—á–∞—Ç–µ–ª–µ–π: {len(fetched_messages.recipient_messages)}")
    logger.info(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–µ–º: {len(fetched_messages.subjects)}")
    
    # –°—Ç–∞—Ç–∏—Å—Ç–∏–∫–∞ –ø–æ –ø–æ–ª—É—á–∞—Ç–µ–ª—è–º
    if fetched_messages.recipient_messages:
        logger.info(f"")
        logger.info(f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π –ø–æ –ø–æ–ª—É—á–∞—Ç–µ–ª—è–º (—Ç–æ–ø-10):")
        sorted_recipients = sorted(
            fetched_messages.recipient_messages.items(), 
            key=lambda x: len(x[1]), 
            reverse=True
        )[:10]
        for recipient, msg_ids in sorted_recipients:
            logger.info(f"  {recipient}: {len(msg_ids)} —Å–æ–±—ã—Ç–∏–µ(–π)")
    
    if matching_events == 0:
        logger.warning("‚ö†Ô∏è  –ù–µ –Ω–∞–π–¥–µ–Ω–æ –Ω–∏ –æ–¥–Ω–æ–≥–æ —Å–æ–±—ã—Ç–∏—è, –ø–æ–¥—Ö–æ–¥—è—â–µ–≥–æ –ø–æ–¥ –∫—Ä–∏—Ç–µ—Ä–∏–∏!")
        if filtered_by_sender > 0:
            logger.warning(f"   {filtered_by_sender} —Å–æ–±—ã—Ç–∏–π –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –ø–æ –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—é")
            logger.warning(f"   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å email –æ—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—è: {sender_email}")
        if filtered_by_time > 0:
            logger.warning(f"   {filtered_by_time} —Å–æ–±—ã—Ç–∏–π –æ—Ç—Ñ–∏–ª—å—Ç—Ä–æ–≤–∞–Ω–æ –ø–æ –≤—Ä–µ–º–µ–Ω–∏")
            logger.warning(f"   –ü—Ä–æ–≤–µ—Ä—å—Ç–µ –ø—Ä–∞–≤–∏–ª—å–Ω–æ—Å—Ç—å –≤—Ä–µ–º–µ–Ω–Ω–æ–≥–æ –¥–∏–∞–ø–∞–∑–æ–Ω–∞:")
            logger.warning(f"   –ú–æ—Å–∫–≤–∞: {datetime_from_moscow.strftime('%H:%M:%S')} - {datetime_to_moscow.strftime('%H:%M:%S')}")
            logger.warning(f"   UTC: {datetime_from.strftime('%H:%M:%S')} - {datetime_to.strftime('%H:%M:%S')}")
    
    return fetched_messages


def is_deletion_approve(sender: str, event_count: int, unique_msgids: int, subjects: set, recipient_messages: dict) -> bool:
    """
    –ó–∞–ø—Ä–∞—à–∏–≤–∞–µ—Ç –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏–µ —É–¥–∞–ª–µ–Ω–∏—è
    """
    logger.info("")
    logger.info(f"=== –ü–û–î–¢–í–ï–†–ñ–î–ï–ù–ò–ï –£–î–ê–õ–ï–ù–ò–Ø ===")
    logger.info(f"–û—Ç–ø—Ä–∞–≤–∏—Ç–µ–ª—å: {sender}")
    logger.info(f"–í—Å–µ–≥–æ —Å–æ–±—ã—Ç–∏–π –∫ –æ–±—Ä–∞–±–æ—Ç–∫–µ: {event_count}")
    logger.info(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö message ID: {unique_msgids}")
    logger.info(f"–£–Ω–∏–∫–∞–ª—å–Ω—ã—Ö —Ç–µ–º: {len(subjects)}")
    
    if subjects:
        logger.info(f"–ü—Ä–∏–º–µ—Ä—ã —Ç–µ–º (–ø–µ—Ä–≤—ã–µ 10):")
        for i, subject in enumerate(list(subjects)[:10]):
            logger.info(f"  {i+1}. {subject}")
    
    logger.info(f"")
    logger.info(f"–ó–∞—Ç—Ä–æ–Ω—É—Ç—ã—Ö –ø–æ–ª—É—á–∞—Ç–µ–ª–µ–π: {len(recipient_messages)}")
    logger.info(f"–†–∞—Å–ø—Ä–µ–¥–µ–ª–µ–Ω–∏–µ —Å–æ–±—ã—Ç–∏–π –ø–æ –ø–æ–ª—É—á–∞—Ç–µ–ª—è–º (–ø–µ—Ä–≤—ã–µ 20):")
    
    sorted_recipients = sorted(
        recipient_messages.items(), 
        key=lambda x: len(x[1]), 
        reverse=True
    )[:20]
    
    for i, (recipient, msg_ids) in enumerate(sorted_recipients):
        logger.info(f"  {i+1}. {recipient}: {len(msg_ids)} —Å–æ–±—ã—Ç–∏–µ(–π)")
    
    if len(recipient_messages) > 20:
        logger.info(f"  ... –∏ –µ—â–µ {len(recipient_messages) - 20}")
    
    logger.info("")
    a = input("‚ö†Ô∏è  –í–≤–µ–¥–∏—Ç–µ 'yes' –¥–ª—è –ø–æ–¥—Ç–≤–µ—Ä–∂–¥–µ–Ω–∏—è —É–¥–∞–ª–µ–Ω–∏—è: ")
    logger.info(f"–í–≤–æ–¥ –ø–æ–ª—å–∑–æ–≤–∞—Ç–µ–ª—è: {a}")
    
    if a.strip().lower() == "yes":
        return True
    return False


class Client360:
    def __init__(self, token: str, org_id: int, client_id: str, secret: str):
        self._token = token
        self._org_id = org_id
        self._id = client_id
        self._secret = secret

    @property
    def audit_log(self):
        return AuditLogAPI(token=self._token, org_id=self._org_id)

    @property
    def user_token(self):
        return UserTokenAPI(client_id=self._id, secret=self._secret)
    
    @property
    def shared_mailboxes(self):
        return SharedMailboxAPI(token=self._token, org_id=self._org_id)


class AuditLogAPI:
    def __init__(self, token: str, org_id: int):
        self._token = token
        self._org_id = org_id

    def get(self, after_date: str, before_date: str,
            page_token: str = "0_0", verify: bool = False):
        url = f"{DEFAULT_360_API_URL}/security/v1/org/{self._org_id}/audit_log/mail"
        headers = {"Authorization": f"OAuth {self._token}"}
        params = {
            "pageSize": AUDIT_LOG_PAGE_SIZE,
            "types": "message_receive",
            "afterDate": after_date,
            "beforeDate": before_date,
            "pageToken": page_token,
        }
        
        session = get_http_session()
        response = session.get(url, headers=headers, params=params, verify=verify)
        
        if response.status_code != HTTPStatus.OK.value:
            logger.error(f"Audit log error: {response.text}")
            raise Client360Error(response.status_code)
        
        audit_log = AuditLog.model_validate(response.json())
        return audit_log


class UserTokenAPI:
    def __init__(self, client_id: str, secret: str):
        self._id = client_id
        self._secret = secret

    def get(self, user_mail: str):
        headers = {
            "Content-Type": "application/x-www-form-urlencoded",
        }
        data = {
            "grant_type": "urn:ietf:params:oauth:grant-type:token-exchange",
            "client_id": self._id,
            "client_secret": self._secret,
            "subject_token": user_mail,
            "subject_token_type": "urn:yandex:params:oauth:token-type:email",
        }
        
        session = get_http_session()
        response = session.post(url=DEFAULT_OAUTH_API_URL, headers=headers, data=data)
        
        if response.status_code != HTTPStatus.OK.value:
            logger.error(
                f"OAuth error for {user_mail}: {response.status_code} - {response.text}"
            )
            raise ClientOAuthError(response.status_code)
        return UserToken.model_validate(response.json())


class SharedMailboxAPI:
    def __init__(self, token: str, org_id: int):
        self._token = token
        self._org_id = org_id

    def list_all(self) -> list[str]:
        url = f"{DEFAULT_360_API_URL}/admin/v1/org/{self._org_id}/mailboxes/shared"
        headers = {"Authorization": f"OAuth {self._token}"}
        params = {"perPage": 100, "page": 1}
        
        all_shared_boxes = []
        
        try:
            session = get_http_session()
            response = session.get(url, headers=headers, params=params, verify=False)
            
            if response.status_code == 403:
                logger.debug("Access denied to shared mailboxes API")
                return []
            
            if response.status_code != HTTPStatus.OK.value:
                logger.debug(f"Error fetching shared mailboxes: {response.status_code}")
                return []
            
            data = response.json()
            mailboxes = data.get("mailboxes", [])
            
            if not mailboxes:
                return []
            
            while mailboxes:
                for mailbox in mailboxes:
                    if mailbox.get("email"):
                        all_shared_boxes.append(mailbox["email"])
                
                pages = data.get("pages", 1)
                current_page = data.get("page", 1)
                
                if current_page >= pages:
                    break
                
                params["page"] += 1
                response = session.get(url, headers=headers, params=params, verify=False)
                
                if response.status_code != HTTPStatus.OK.value:
                    break
                    
                data = response.json()
                mailboxes = data.get("mailboxes", [])
        
        except Exception as e:
            logger.debug(f"Exception fetching shared mailboxes: {e}")
        
        return all_shared_boxes


class DeletionStatus(enum.Enum):
    NotFound = "Not Found"
    Empty = "Empty"
    Deleted = "Deleted"


@dataclass
class SettingParams:
    oauth_token: str
    organization_id: int
    app_client_id: str
    app_client_secret: str


@dataclass
class FetchedMessages:
    """–•—Ä–∞–Ω–∏—Ç –∏–Ω—Ñ–æ—Ä–º–∞—Ü–∏—é –æ –Ω–∞–π–¥–µ–Ω–Ω—ã—Ö –ø–∏—Å—å–º–∞—Ö —Å –ø—Ä–∏–≤—è–∑–∫–æ–π –∫ –ø–æ–ª—É—á–∞—Ç–µ–ª—è–º"""
    recipient_messages: Dict[str, set]  # recipient -> set of message_ids –¥–ª—è —ç—Ç–æ–≥–æ –ø–æ–ª—É—á–∞—Ç–µ–ª—è
    all_message_ids: set  # –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ message_ids (–¥–ª—è —Å—Ç–∞—Ç–∏—Å—Ç–∏–∫–∏)
    subjects: set  # –≤—Å–µ —É–Ω–∏–∫–∞–ª—å–Ω—ã–µ —Ç–µ–º—ã


class AuditLog(BaseModel):
    events: list[Union["AuditLogEvents"]]
    nextPageToken: str


def convert_datetime(date: str) -> datetime:
    return datetime.strptime(date, "%Y-%m-%dT%H:%M:%S.%fZ")


class AuditLogEvents(BaseModel):
    model_config = ConfigDict(populate_by_name=True)
    
    eventType: str
    orgId: int
    userUid: str
    userLogin: str
    userName: str
    requestId: str
    uniqId: str
    source: str
    clientIp: str
    date: datetime = Field(default_factory=lambda: datetime.now())
    mid: str
    folderName: str
    folderType: str
    labels: list
    msgId: str
    subject: str
    from_: str = Field(alias="from")
    to: str
    cc: str
    bcc: str
    
    def __init__(self, **data):
        super().__init__(**data)
        if isinstance(self.date, str):
            self.date = convert_datetime(self.date)

        if hasattr(self.date, 'tzinfo') and self.date.tzinfo is not None:
            self.date = self.date.replace(tzinfo=None)


class UserToken(BaseModel):
    access_token: str
    expires_in: int
    issued_token_type: str
    scope: Optional[str] = None
    token_type: str


class ToolError(Exception):
    def __init__(self, *args):
        if args:
            self.msg = args[0]
        else:
            self.msg = None

    def __str__(self):
        return self.msg


class Client360Error(ToolError):
    def __str__(self):
        match self.msg:
            case 403:
                return "No access rights to the resource."
            case 401:
                return "Invalid user token."
            case _:
                return f"Unexpected status code: {self.msg}"


class ClientOAuthError(ToolError):
    def __str__(self):
        match self.msg:
            case 400:
                return "Invalid application client id or secret"
            case _:
                return f"Unexpected status code: {self.msg}"


if __name__ == "__main__":
    try:
        main()
    except ToolError as err:
        logging.error(err)
        sys.exit(EXIT_CODE)
    except Exception as exp:
        logging.exception(exp)
        sys.exit(EXIT_CODE)
